## The number of worker processes, should be the same as your number
## of cores.
nworkers: 16
logfile: tlsproxy.log
## Log levels are: FATAL ERROR WARN INFO DEBUG
loglevel: DEBUG

listeners:
  - name: https
    ## Connection details of the backend server
    target-ip: 127.0.0.1
    target-port: 8080

    ## If we can't connect to the server by this time, drop the connection
    connect-timeout: 5000

    ## The proxy will accept connections on <listen-ip>:<listen-port>
    ## 0.0.0.0 means listen on every interface
    listen-ip: 0.0.0.0
    listen-port: 8443

    ## The certificate chain offered to clients
    cacerts:
      - cacert.pem
      - intcert.pem
    servcert: servcert.pem
    servkey: servkey.pem
    ## If the servkey is encrypted:
    #servkeypass: test

  ## Basic load balancing
  # - name: https2
  #   target-ip: 127.0.0.1
  #   target-port: 8081

  #   connect-timeout: 6000

  #   ## Note we're using the same IP/port combo for the listen socket
  #   ## That's right, we get basic load balancing too!
  #   listen-ip: 0.0.0.0
  #   listen-port: 8443

  #   ## The certificate chain offered to clients
  #   cert-chain: chain.pem
  #   servkey: servkey.pem

  ## Pointing to another service
  # - name: telnets
  #   target-ip: 127.0.0.1
  #   target-port: 23

  #   connect-timeout: 2000

  #   listen-ip: 0.0.0.0
  #   listen-port: 42023

  #   ## The certificate chain offered to clients
  #   cert-chain: chain.pem
  #   servkey: servkey.pem
